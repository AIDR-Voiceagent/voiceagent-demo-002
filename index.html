<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AI Voice Demo</title>

  <style>
    :root{
      --bg:#000;
      --card:#0f0f10;
      --muted:#bdbdbd;
      --accent:#00ff9d;
      --glow:rgba(255,255,255,0.25);
    }

    html,body{
      height:100%;
      margin:0;
      background:var(--bg);
      font-family:Arial,Helvetica,sans-serif;
      color:#fff;
    }

    .page-wrap{
      min-height:100%;
      display:flex;
      align-items:center;
      justify-content:center;
      padding:28px;
    }

    .card{
      width:78%;
      max-width:920px;
      background:linear-gradient(180deg,#121212 0,#0f0f10 100%);
      border-radius:18px;
      padding:36px;
      box-shadow:0 0 45px var(--glow);
      border:1px solid rgba(255,255,255,0.04);
      text-align:center;
    }

    h1{margin-bottom:18px;font-size:28px;}

    .controls{
      display:flex;
      gap:18px;
      justify-content:center;
      margin-bottom:12px;
    }

    .btn{
      padding:11px 28px;
      border-radius:10px;
      border:1px solid rgba(255,255,255,0.08);
      cursor:pointer;
      font-weight:600;
      color:#fff;
      font-size:15px;
      background:rgba(255,255,255,0.04);
    }

    .status{
      color:var(--muted);
      margin:6px 0 18px;
      font-weight:600;
    }

    .mic-bubble{
      width:86px;
      height:86px;
      border-radius:50%;
      margin:14px auto;
      display:flex;
      align-items:center;
      justify-content:center;
      border:2px solid rgba(255,255,255,0.12);
      box-shadow:0 0 25px rgba(255,255,255,0.15);
    }

    .mic-bubble.active{
      box-shadow:0 0 35px rgba(255,255,255,0.45);
    }

    .volume-bar{
      width:60%;
      height:8px;
      margin:10px auto;
      background:#222;
      border-radius:6px;
      overflow:hidden;
    }

    .volume-fill{
      height:100%;
      width:0%;
      background:#fff;
      transition:width .05s linear;
    }

    .transcript-box{
      width:86%;
      max-width:760px;
      height:180px;
      background:#151515;
      border-radius:10px;
      margin:14px auto 0;
      padding:14px 16px;
      overflow-y:auto;
      font-size:14px;
      text-align:left;
    }

    .msg-user{color:var(--accent);margin-bottom:8px;font-weight:600}
    .msg-agent{margin-bottom:8px;opacity:.95}
  </style>
</head>

<body>
<div class="page-wrap">
  <div class="card">
    <h1>AI Voice Demo</h1>

    <div class="controls">
      <button id="connectBtn" class="btn">Verbinden</button>
      <button id="stopBtn" class="btn">Stop</button>
    </div>

    <div id="statusText" class="status">Bereit.</div>

    <div id="micBubble" class="mic-bubble">MIC</div>

    <div class="volume-bar">
      <div id="volFill" class="volume-fill"></div>
    </div>

    <div id="transcriptBox" class="transcript-box"></div>
  </div>
</div>

<!-- ðŸ”’ FESTE, STABILE VAPI VERSION (KEIN latest!) -->
<script src="https://unpkg.com/@vapi-ai/web@0.0.12/dist/index.umd.js"></script>

<script>
  const PUBLIC_KEY = "3857a4fd-9664-470b-b523-759ca2db2753";
  const ASSISTANT_ID = "9939aaaf-23ff-490a-8daf-665758ff117b";

  const statusText = document.getElementById("statusText");
  const transcriptBox = document.getElementById("transcriptBox");
  const micBubble = document.getElementById("micBubble");
  const volFill = document.getElementById("volFill");

  let vapi = null;
  let call = null;
  let audioCtx, analyser, raf;

  function addMsg(text, cls){
    const d = document.createElement("div");
    d.className = cls;
    d.textContent = text;
    transcriptBox.appendChild(d);
    transcriptBox.scrollTop = transcriptBox.scrollHeight;
  }

  function getVapi(){
    if (window.Vapi) return window.Vapi;
    if (window.Vapi?.default) return window.Vapi.default;
    throw new Error("VAPI SDK nicht geladen");
  }

  async function startVisualizer(stream){
    audioCtx = new AudioContext();
    const src = audioCtx.createMediaStreamSource(stream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256;
    const data = new Uint8Array(analyser.frequencyBinCount);
    src.connect(analyser);

    const loop = ()=>{
      analyser.getByteTimeDomainData(data);
      let sum=0;
      for(let i=0;i<data.length;i++){
        const v=data[i]-128;
        sum+=v*v;
      }
      const vol=Math.min(1,Math.sqrt(sum/data.length)/50);
      volFill.style.width=(vol*100)+"%";
      micBubble.classList.toggle("active",vol>0.15);
      raf=requestAnimationFrame(loop);
    };
    loop();
  }

  document.getElementById("connectBtn").onclick = async ()=>{
    try{
      statusText.textContent="Verbindenâ€¦";

      const stream = await navigator.mediaDevices.getUserMedia({audio:true});
      await startVisualizer(stream);

      const VapiCtor = getVapi();
      vapi = new VapiCtor(PUBLIC_KEY);

      call = await vapi.start({
        assistantId: ASSISTANT_ID,
        audio:{ input:stream, output:true }
      });

      statusText.textContent="Verbunden";

      call.on("transcript", e=>{
        if(e?.text){
          addMsg(
            (e.role==="user"?"Du: ":"Agent: ")+e.text,
            e.role==="user"?"msg-user":"msg-agent"
          );
        }
      });

      call.on("close", ()=>statusText.textContent="Getrennt");
      call.on("error", e=>console.error(e));

    }catch(err){
      console.error(err);
      statusText.textContent="Browser / Mikrofon / SDK Problem";
    }
  };

  document.getElementById("stopBtn").onclick = ()=>{
    if(call) call.stop();
    if(audioCtx) audioCtx.close();
    cancelAnimationFrame(raf);
    volFill.style.width="0%";
    micBubble.classList.remove("active");
    statusText.textContent="Getrennt";
  };
</script>
</body>
</html>
